"""Streamlit ì•± - UI Layer"""
import os
import sys
import asyncio
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import streamlit as st
from dotenv import load_dotenv

from src.chatbot.service import ChatbotService
from src.chatbot.entities import ChatbotConfig

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì£¼ê°€ ê³„ì‚° ì±—ë´‡ v2.0",
    page_icon="ğŸ’°",
    layout="centered"
)


@st.cache_resource
def init_chatbot():
    """ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ì˜ì¡´ì„± ì£¼ì…)"""
    try:
        from src.chatbot.container import chatbot_container
        return chatbot_container.service()
    except Exception as e:
        st.error(f"ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None


def check_environment():
    """í™˜ê²½ ì„¤ì • ì²´í¬"""
    if not os.getenv("OPENAI_API_KEY"):
        st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        st.info("ğŸ“ .env íŒŒì¼ì— OPENAI_API_KEY=your_api_key_hereë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”")
        st.stop()


def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    # í™˜ê²½ ì²´í¬
    check_environment()
    
    # ì œëª©
    st.title("ğŸ’° ì£¼ê°€ ê³„ì‚° ì±—ë´‡ v2.0")
    st.caption("ğŸ—ï¸ Layered Architecture + uv + LangGraph")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'session_id' not in st.session_state:
        st.session_state.session_id = f"streamlit_{int(time.time())}"
    
    # ì±—ë´‡ ì„œë¹„ìŠ¤ ë¡œë“œ
    chatbot_service = init_chatbot()
    if chatbot_service is None:
        st.stop()
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ì•„í‚¤í…ì²˜ ì •ë³´
        with st.expander("ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì •ë³´"):
            st.markdown("""
            **ìƒˆë¡œìš´ Layered Architecture:**
            - `src/chatbot/` - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
            - `src/llm/` - LLM ì¶”ìƒí™”
            - `src/tools/` - ë„êµ¬ ì„œë¹„ìŠ¤
            - `src/model/executors/` - ì‹¤í–‰ê¸°
            - `webapp/` - Presentation Layer
            """)
        
        # ì„¸ì…˜ ì´ˆê¸°í™”
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            try:
                chatbot_service.clear_session(st.session_state.session_id)
                st.session_state.messages = []
                st.success("ëŒ€í™”ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            except Exception as e:
                st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        st.divider()
        st.caption(f"Session: {st.session_state.session_id}")
    
    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: AAPL ì£¼ê°€ ì•Œë ¤ì¤˜)"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)
        
        # AI ì‘ë‹µ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            
            try:
                async def get_streaming_response():
                    full_response = ""
                    streaming_response = await chatbot_service.stream_chat(
                        st.session_state.session_id, 
                        prompt
                    )
                    
                    async for chunk in streaming_response.generator:
                        # ë°±ì—”ë“œì—ì„œ ë°›ì€ ì²­í¬ë¥¼ ë¬¸ìë³„ë¡œ íƒ€ì´í•‘ íš¨ê³¼ ì ìš©
                        for char in chunk:
                            full_response += char
                            response_placeholder.write(full_response + "â–‹")  # ì»¤ì„œ íš¨ê³¼
                            await asyncio.sleep(0.03)  # íƒ€ì´í•‘ ì†ë„ ì¡°ì ˆ
                        
                        # ì²­í¬ ì™„ë£Œ í›„ ì»¤ì„œ ì œê±°
                        response_placeholder.write(full_response)
                    
                    return full_response
                
                # ë¹„ë™ê¸° ì‹¤í–‰
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                final_response = loop.run_until_complete(get_streaming_response())
                loop.close()
                
                if final_response:
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": final_response
                    })
                else:
                    st.error("âŒ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")
    
    # í•˜ë‹¨ ì •ë³´
    with st.expander("â„¹ï¸ ì‚¬ìš©ë²• ë° ì˜ˆì‹œ"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **ì£¼ê°€ ì¡°íšŒ:**
            - "AAPL ì£¼ê°€ ì•Œë ¤ì¤˜"
            - "í…ŒìŠ¬ë¼ ì£¼ì‹ ê°€ê²©ì€?"
            - "NVDA í˜„ì¬ê°€ í™•ì¸í•´ì¤˜"
            """)
        
        with col2:
            st.markdown("""
            **ê³„ì‚°:**
            - "100 * 1.5ëŠ”?"
            - "sqrt(16) ê³„ì‚°í•´ì¤˜"
            - "2 + 3 * 4"
            """)
        
        st.markdown("""
        **ë³µí•© ì§ˆë¬¸:**
        - "ì—”ë¹„ë””ì•„ 5ì£¼ë‘ ì•„ë§ˆì¡´ 8ì£¼ë¥¼ ë‘ëª…ì´ ëˆì„ ëª¨ì•„ ì‚¬ë ¤ê³  í•˜ëŠ”ë°, ê°ì ì–¼ë§ˆë‚˜ ëˆ ì±™ê²¨ì•¼ í•´?"
        """)


if __name__ == "__main__":
    main()
